import torch

def CheckGPU():
    print("=" * 50)
    print("üñ•Ô∏è  GPU INFORMATION")
    print("=" * 50)

    if torch.cuda.is_available():
        device_id = 0
        device = torch.device("cuda")
        props = torch.cuda.get_device_properties(device_id)
        
        print(f"‚úÖ GPU Detected         : {props.name}")
        print(f"   ‚Ä¢ Device ID          : {device_id}")
        print(f"   ‚Ä¢ Compute Capability : {props.major}.{props.minor}")
        print(f"   ‚Ä¢ Multiprocessors    : {props.multi_processor_count}")
        print(f"   ‚Ä¢ Total VRAM         : {props.total_memory / (1024 ** 3):.2f} GB")

        # Optional: check allocated and reserved memory
        torch.cuda.empty_cache()
        allocated = torch.cuda.memory_allocated(device_id) / (1024 ** 3)
        reserved = torch.cuda.memory_reserved(device_id) / (1024 ** 3)
        print(f"   ‚Ä¢ VRAM Allocated     : {allocated:.2f} GB")
        print(f"   ‚Ä¢ VRAM Reserved      : {reserved:.2f} GB")
        print(f"   ‚Ä¢ Active Device      : {device}")

    else:
        print("‚ùå No GPU detected.")
        print(f"   ‚Ä¢ Active Device      : CPU")

    print("=" * 50)

def CheckGPUBrief():
    if torch.cuda.is_available():
        props = torch.cuda.get_device_properties(0)
        vram_gb = props.total_memory / (1024 ** 3)
        cudnn_ver = torch.backends.cudnn.version()
        print(f"üü¢ GPU: {props.name} | üíæ VRAM: {vram_gb:.2f} GB")
        print(f"üß† PyTorch: {torch.__version__} | üß∞ cuDNN: {cudnn_ver}")
    else:
        print("üî¥ No GPU detected ‚Äî using CPU")
        print(f"üß† PyTorch: {torch.__version__} | üß∞ cuDNN: N/A")
    

def CheckCUDA():
    print("\n" + "=" * 50)
    print("‚ö° CUDA / PYTORCH INFORMATION")
    print("=" * 50)

    cuda_available = torch.cuda.is_available()
    print(f"{'‚úÖ' if cuda_available else '‚ùå'} CUDA Available       : {cuda_available}")
    print(f"   ‚Ä¢ PyTorch CUDA Ver.  : {torch.version.cuda}")
    print(f"   ‚Ä¢ PyTorch Version    : {torch.__version__}")

    if cuda_available:
        print(f"‚úÖ cuDNN Version        : {torch.backends.cudnn.version()}")
        print(f"   ‚Ä¢ CUDA Device Count  : {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"   ‚Ä¢ Device {i} Name     : {torch.cuda.get_device_name(i)}")
    else:
        print("‚ùå cuDNN Version        : Not available (No GPU)")

    print("=" * 50)
