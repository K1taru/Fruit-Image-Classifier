{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ba1ab1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch CUDA version: 11.8\n",
      "Is CUDA available? True\n",
      "Using device: cuda\n",
      "NVIDIA GeForce RTX 2060\n",
      "Batch 1/100, Loss: 6.8609\n",
      "Batch 2/100, Loss: 5.4256\n",
      "Batch 3/100, Loss: 4.9902\n",
      "Batch 4/100, Loss: 3.8285\n",
      "Batch 5/100, Loss: 4.4995\n",
      "Batch 6/100, Loss: 4.7416\n",
      "Batch 7/100, Loss: 5.9733\n",
      "Batch 8/100, Loss: 6.2366\n",
      "Batch 9/100, Loss: 7.4635\n",
      "Batch 10/100, Loss: 7.3379\n",
      "Batch 11/100, Loss: 5.5281\n",
      "Batch 12/100, Loss: 7.4132\n",
      "Batch 13/100, Loss: 8.5486\n",
      "Batch 14/100, Loss: 5.5094\n",
      "Batch 15/100, Loss: 7.5803\n",
      "Batch 16/100, Loss: 6.9795\n",
      "Batch 17/100, Loss: 4.6297\n",
      "Batch 18/100, Loss: 9.4810\n",
      "Batch 19/100, Loss: 6.1554\n",
      "Batch 20/100, Loss: 11.3457\n",
      "Batch 21/100, Loss: 6.2831\n",
      "Batch 22/100, Loss: 5.6082\n",
      "Batch 23/100, Loss: 8.8171\n",
      "Batch 24/100, Loss: 4.6026\n",
      "Batch 25/100, Loss: 5.8157\n",
      "Batch 26/100, Loss: 4.6149\n",
      "Batch 27/100, Loss: 6.3279\n",
      "Batch 28/100, Loss: 9.2567\n",
      "Batch 29/100, Loss: 7.1432\n",
      "Batch 30/100, Loss: 5.0765\n",
      "Batch 31/100, Loss: 6.2893\n",
      "Batch 32/100, Loss: 6.2363\n",
      "Batch 33/100, Loss: 6.1689\n",
      "Batch 34/100, Loss: 7.3953\n",
      "Batch 35/100, Loss: 6.0339\n",
      "Batch 36/100, Loss: 4.7506\n",
      "Batch 37/100, Loss: 6.4776\n",
      "Batch 38/100, Loss: 3.4531\n",
      "Batch 39/100, Loss: 3.7109\n",
      "Batch 40/100, Loss: 3.9678\n",
      "Batch 41/100, Loss: 3.4988\n",
      "Batch 42/100, Loss: 7.0417\n",
      "Batch 43/100, Loss: 4.6339\n",
      "Batch 44/100, Loss: 5.1267\n",
      "Batch 45/100, Loss: 7.4563\n",
      "Batch 46/100, Loss: 5.2929\n",
      "Batch 47/100, Loss: 6.7503\n",
      "Batch 48/100, Loss: 5.0456\n",
      "Batch 49/100, Loss: 5.9223\n",
      "Batch 50/100, Loss: 8.3264\n",
      "Batch 51/100, Loss: 6.6794\n",
      "Batch 52/100, Loss: 5.3985\n",
      "Batch 53/100, Loss: 6.1582\n",
      "Batch 54/100, Loss: 5.0133\n",
      "Batch 55/100, Loss: 5.0316\n",
      "Batch 56/100, Loss: 7.3630\n",
      "Batch 57/100, Loss: 4.5674\n",
      "Batch 58/100, Loss: 6.8542\n",
      "Batch 59/100, Loss: 4.6242\n",
      "Batch 60/100, Loss: 7.4659\n",
      "Batch 61/100, Loss: 8.6962\n",
      "Batch 62/100, Loss: 7.9581\n",
      "Batch 63/100, Loss: 7.3048\n",
      "Batch 64/100, Loss: 6.4207\n",
      "Batch 65/100, Loss: 5.8944\n",
      "Batch 66/100, Loss: 5.6916\n",
      "Batch 67/100, Loss: 7.0170\n",
      "Batch 68/100, Loss: 7.3003\n",
      "Batch 69/100, Loss: 4.1850\n",
      "Batch 70/100, Loss: 4.3232\n",
      "Batch 71/100, Loss: 3.8055\n",
      "Batch 72/100, Loss: 2.7420\n",
      "Batch 73/100, Loss: 4.8501\n",
      "Batch 74/100, Loss: 4.2782\n",
      "Batch 75/100, Loss: 5.8966\n",
      "Batch 76/100, Loss: 7.7390\n",
      "Batch 77/100, Loss: 5.3915\n",
      "Batch 78/100, Loss: 6.5967\n",
      "Batch 79/100, Loss: 5.0805\n",
      "Batch 80/100, Loss: 7.5968\n",
      "Batch 81/100, Loss: 6.1465\n",
      "Batch 82/100, Loss: 3.5483\n",
      "Batch 83/100, Loss: 5.1883\n",
      "Batch 84/100, Loss: 7.4858\n",
      "Batch 85/100, Loss: 4.4611\n",
      "Batch 86/100, Loss: 5.0821\n",
      "Batch 87/100, Loss: 5.0593\n",
      "Batch 88/100, Loss: 6.7747\n",
      "Batch 89/100, Loss: 6.1176\n",
      "Batch 90/100, Loss: 4.0791\n",
      "Batch 91/100, Loss: 4.0314\n",
      "Batch 92/100, Loss: 4.6806\n",
      "Batch 93/100, Loss: 5.7653\n",
      "Batch 94/100, Loss: 8.0753\n",
      "Batch 95/100, Loss: 5.7974\n",
      "Batch 96/100, Loss: 6.5210\n",
      "Batch 97/100, Loss: 8.9980\n",
      "Batch 98/100, Loss: 5.3915\n",
      "Batch 99/100, Loss: 7.2445\n",
      "Batch 100/100, Loss: 6.6077\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "\n",
    "# --- Check CUDA ---\n",
    "print(\"PyTorch CUDA version:\", torch.version.cuda)\n",
    "print(\"Is CUDA available?\", torch.cuda.is_available())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "print(torch.cuda.get_device_name(0))  # Should print 'NVIDIA GeForce RTX 2060'\n",
    "\n",
    "# --- Model ---\n",
    "model = models.resnet50(pretrained=False).to(device)\n",
    "\n",
    "# --- Dummy dataset ---\n",
    "batch_size = 16\n",
    "num_classes = 10\n",
    "num_batches = 100  # Just to test\n",
    "\n",
    "# Random inputs and labels\n",
    "dataloader = [\n",
    "    (torch.randn(batch_size, 3, 224, 224), torch.randint(0, num_classes, (batch_size,)))\n",
    "    for _ in range(num_batches)\n",
    "]\n",
    "\n",
    "# --- Loss & optimizer ---\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# --- Training loop ---\n",
    "for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Batch {batch_idx+1}/{num_batches}, Loss: {loss.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
